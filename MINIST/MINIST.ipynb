{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 手写数字识别任务\n",
    "\n",
    "手写数字识别解决了邮政系统邮政编码识别的问题。手写数字识别常用的数据集是 mnist，该数据集是入门机器学习、深度学习 经典的数据集。  \n",
    "\n",
    "MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取, 它包含了四个部分:  \n",
    "Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本)  \n",
    "Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签)  \n",
    "Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本)  \n",
    "Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签)  \n",
    "\n",
    "MNIST 数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST). 训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据.\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/b7c9379268e74660930fb9fdacaff006310a62d3b4334b6a8f05458e791478a6\" width=\"600\" hegiht=\"40\" ></center>  \n",
    "MNIST数据集的发布，吸引了大量科学家训练模型。1998年，LeCun分别用单层线性分类器、多层感知器（Multilayer Perceptron, MLP）和多层卷积神经网络LeNet进行实验，使得测试集的误差不断下降（从12%下降到0.7%）。在研究过程中，LeCun提出了卷积神经网络（Convolutional Neural Network，CNN），大幅度地提高了手写字符的识别能力，也因此成为了深度学习领域的奠基人之一。  \n",
    "\n",
    "* 任务输入：一系列手写数字图片，其中每张图片都是28x28的像素矩阵。\n",
    "* 任务输出：经过了大小归一化和居中处理，输出对应的0~9的数字标签。\n",
    "\n",
    "\n",
    "## 构建手写数字识别的神经网络模型\n",
    "\n",
    "使用飞桨完成手写数字识别模型任务的代码结构如图所示，与使用飞桨完成房价预测模型任务的流程一致，下面的章节中我们将详细介绍每个步骤的具体实现方法和优化思路。\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/38b467ff3b6e4705b9b4d34c6b13431073e449640ef847f396923475b11c913b\" width=\"800\" hegiht=\"\" ></center>\n",
    "<br></br>\n",
    "\n",
    "这里的每个模块都有可以配置的不同选项，类似于小朋友插积木，在这个模式固定的框架上更换各种组件，来适应不同需求。  \n",
    "下面来看一下各个模块的可以插拔的组件。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "深度学习的代码结构是“套路”型的。按照固定的套路，替换部分部件就可以完成对应功能，系统的结构如下图所示：\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/82a84e5e3d054c858c65cf5f8988394950e6945c1a5c4d378ce9ead92c0fb91d\"  width=\"800\" ></center>\n",
    "\n",
    "接下来我们展示手写数字识别的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载飞桨、Numpy和相关类库\r\n",
    "import os\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "import gzip\r\n",
    "import json\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据处理\n",
    "### 手写数字的数据处理\n",
    "MNIST数据集以json格式存储在本地，其数据存储结构如图所示。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/7d278024d7ac4d6689fdbe0aa1729181699444730e3941d386a55a1ff8ab4276\" width=\"500\" hegiht=\"\" ></center>\n",
    "\n",
    "**data**包含三个元素的列表：**train_set**、**val_set**、 **test_set**，包括50000条训练样本、10000条验证样本、10000条测试样本。每个样本包含手写数字图片和对应的标签。\n",
    "\n",
    "* **train_set（训练集）**：用于确定模型参数。\n",
    "* **val_set（验证集）**：用于调节模型超参数（如多个网络结构、正则化权重的最优选择）。\n",
    "* **test_set（测试集）**：用于估计应用效果（没有在模型中应用过的数据，更贴近模型在真实场景应用的效果）。\n",
    "\n",
    "**train_set**包含两个元素的列表：**train_images**、**train_labels**。\n",
    "\n",
    "* **train_images**：[50000, 784]的二维列表，包含50000张图片。每张图片用一个长度为784的向量表示，内容是28\\*28尺寸的像素灰度值（黑白图片）。\n",
    "* **train_labels**：[50000, ]的列表，表示这些图片对应的分类标签，即0-9之间的一个数字。\n",
    "\n",
    "在本地`./work/`目录下读取文件名称为`mnist.json.gz`的MNIST数据，并拆分成训练集、验证集和测试集，实现方法如下所示。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "# 定义数据集读取器\r\n",
    "def load_data(mode):\r\n",
    "\r\n",
    "    # 数据文件\r\n",
    "    datafile = './work/mnist.json.gz'\r\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\r\n",
    "    data = json.load(gzip.open(datafile))\r\n",
    "    train_set, val_set, eval_set = data\r\n",
    "\r\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\r\n",
    "    IMG_ROWS = 28\r\n",
    "    IMG_COLS = 28\r\n",
    "\r\n",
    "    if mode == 'train':\r\n",
    "        imgs = train_set[0]\r\n",
    "        labels = train_set[1]\r\n",
    "    elif mode == 'valid':\r\n",
    "        imgs = val_set[0]\r\n",
    "        labels = val_set[1]\r\n",
    "    elif mode == 'eval':\r\n",
    "        imgs = eval_set[0]\r\n",
    "        labels = eval_set[1]\r\n",
    "\r\n",
    "    imgs_length = len(imgs)\r\n",
    "\r\n",
    "    # 校验\r\n",
    "    assert len(imgs) == len(labels), \\\r\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\r\n",
    "                  len(imgs), len(labels))\r\n",
    "\r\n",
    "    print('数据集校验正常')\r\n",
    "    print(len(imgs))\r\n",
    "    index_list = list(range(imgs_length))\r\n",
    "\r\n",
    "    # 读入数据时用到的batchsize\r\n",
    "    BATCHSIZE = 100 #调试修改，调参 128/64\r\n",
    "\r\n",
    "    # 定义数据生成器\r\n",
    "    def data_generator():\r\n",
    "        if mode == 'train':\r\n",
    "            random.shuffle(index_list)\r\n",
    "        imgs_list = []\r\n",
    "        labels_list = []\r\n",
    "        for i in index_list:\r\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\r\n",
    "            label = np.reshape(labels[i], [1]).astype('int64')\r\n",
    "            imgs_list.append(img) \r\n",
    "            labels_list.append(label)\r\n",
    "            if len(imgs_list) == BATCHSIZE and mode == 'train':\r\n",
    "                yield np.array(imgs_list), np.array(labels_list)\r\n",
    "                imgs_list = []\r\n",
    "                labels_list = []\r\n",
    "\r\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\r\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\r\n",
    "        if len(imgs_list) > 0 or mode == 'eval':\r\n",
    "            yield np.array(imgs_list), np.array(labels_list)\r\n",
    "\r\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 卷积网络结构\r\n",
    "class MNIST(fluid.dygraph.Layer):\r\n",
    "     def __init__(self):\r\n",
    "         super(MNIST, self).__init__()\r\n",
    "         \r\n",
    "         # 定义一个卷积层，使用relu激活函数\r\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\r\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\r\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\r\n",
    "         # 定义一个卷积层，使用relu激活函数\r\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\r\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\r\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\r\n",
    "         # 定义一层全连接输出层，输出维度是10\r\n",
    "         self.fc = Linear(input_dim=980, output_dim=10, act='softmax')\r\n",
    "    # 定义网络的前向计算过程\r\n",
    "     def forward(self, inputs):\r\n",
    "         x = self.conv1(inputs)\r\n",
    "         x = self.pool1(x)\r\n",
    "         x = self.conv2(x)\r\n",
    "         x = self.pool2(x)\r\n",
    "         x = fluid.layers.reshape(x, [x.shape[0], 980])\r\n",
    "         x = self.fc(x)\r\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from ./work/mnist.json.gz ......\n"
     ]
    }
   ],
   "source": [
    "with fluid.dygraph.guard():    \r\n",
    "    # 声明定义好的线性回归模型\r\n",
    "    model = MNIST()\r\n",
    "    # 开启模型训练模式\r\n",
    "    model.train()\r\n",
    "    #调用加载数据的函数\r\n",
    "    train_loader = load_data('train')\r\n",
    "    # 定义优化算法，这里使用随机梯度下降-SGD\r\n",
    "    # 学习率设置为0.01\r\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#仅修改计算损失的函数，从均方误差（常用于回归问题）到交叉熵误差（常用于分类问题）\r\n",
    "with fluid.dygraph.guard():\r\n",
    "    EPOCH_NUM = 5\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            #准备数据，变得更加简洁\r\n",
    "            image_data, label_data = data\r\n",
    "            image = fluid.dygraph.to_variable(image_data)\r\n",
    "            label = fluid.dygraph.to_variable(label_data)\r\n",
    "            \r\n",
    "            #前向计算的过程\r\n",
    "            predict = model(image)\r\n",
    "            \r\n",
    "            #计算损失，使用交叉熵损失函数，取一个批次样本损失的平均值\r\n",
    "            loss = fluid.layers.cross_entropy(predict, label)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "            \r\n",
    "            #每训练了200批次的数据，打印下当前Loss的情况\r\n",
    "            if batch_id % 50 == 0:\r\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\r\n",
    "            \r\n",
    "            #后向传播，更新参数的过程\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.minimize(avg_loss)\r\n",
    "            model.clear_gradients()\r\n",
    "\r\n",
    "    #保存模型参数\r\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 测试\n",
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取一张本地的样例图片，转变成模型输入的格式\r\n",
    "def load_image(img_path):\r\n",
    "    # 从img_path中读取图像，并转为灰度图\r\n",
    "    im = Image.open(img_path).convert('L')\r\n",
    "    im.show()\r\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\r\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)\r\n",
    "    # 图像归一化\r\n",
    "    im = 1.0 - im / 255.\r\n",
    "    return im\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义预测过程\r\n",
    "with fluid.dygraph.guard():\r\n",
    "    model = MNIST()\r\n",
    "    params_file_path = 'mnist'\r\n",
    "    img_path = './work/example_0.jpg'\r\n",
    "    # 加载模型参数\r\n",
    "    model_dict, _ = fluid.load_dygraph(\"mnist\")\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    \r\n",
    "    model.eval()\r\n",
    "    tensor_img = load_image(img_path)\r\n",
    "    #模型反馈10个分类标签的对应概率\r\n",
    "    results = model(fluid.dygraph.to_variable(tensor_img))\r\n",
    "    #取概率最大的标签作为预测输出\r\n",
    "    lab = np.argsort(results.numpy())\r\n",
    "    print(\"本次预测的数字是: \", lab[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 请编写 预测统计 正确率的代码 并 输出正确率\r\n",
    "with fluid.dygraph.guard(): \r\n",
    "    correct_prediction = 0\r\n",
    "    prediction = 0\r\n",
    "    test_loader = load_data('eval')\r\n",
    "    \r\n",
    "    model_dict, _ = fluid.load_dygraph(\"mnist\")\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    \r\n",
    "    model.eval()\r\n",
    "    for index, data in enumerate(test_loader()):\r\n",
    "        #准备数据，变得更加简洁\r\n",
    "        image_data, label_data = data\r\n",
    "        image = fluid.dygraph.to_variable(image_data)\r\n",
    "        label = fluid.dygraph.to_variable(label_data)\r\n",
    "        \r\n",
    "        #前向计算的过程\r\n",
    "        predict = model(image)\r\n",
    "        pre = np.argsort(predict.numpy())\r\n",
    "\r\n",
    "        for i in range(len(pre)):\r\n",
    "            if label[i][-1] == pre[i][-1]:\r\n",
    "                correct_prediction += 1\r\n",
    "            prediction += 1\r\n",
    "    accuracy = correct_prediction / prediction\r\n",
    "    print(\"正确率: \",accuracy)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
